[
  {
    "objectID": "working_files/analysis_files/grupo_uno_paso_dos.html",
    "href": "working_files/analysis_files/grupo_uno_paso_dos.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "import polars as pl\nimport sqlite3\nimport plotly.express as px\nimport missingno as msno\n\nimport using polars (something newâ€¦)\n\njobs = pl.read_csv(\"lightcast_job_postings.csv\")\n\n\nprint(jobs.shape)\n\n(72476, 131)\n\n\n\nprint(jobs.columns)\n\n['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\nschema = pl.DataFrame({\n    'Column': jobs.columns,\n    'Data Type': jobs.dtypes,\n    'Unique Values': [jobs.select(pl.col(col).n_unique()).item() for col in jobs.columns]\n})\n\nprint(schema.shape)\n\n(131, 3)\n\n\n\nprint(schema.head(20))\n\nshape: (20, 3)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Column                 â”† Data Type â”† Unique Values â”‚\nâ”‚ ---                    â”† ---       â”† ---           â”‚\nâ”‚ str                    â”† object    â”† i64           â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ ID                     â”† String    â”† 72476         â”‚\nâ”‚ LAST_UPDATED_DATE      â”† String    â”† 169           â”‚\nâ”‚ LAST_UPDATED_TIMESTAMP â”† String    â”† 174           â”‚\nâ”‚ DUPLICATES             â”† Int64     â”† 72            â”‚\nâ”‚ POSTED                 â”† String    â”† 153           â”‚\nâ”‚ â€¦                      â”† â€¦         â”† â€¦             â”‚\nâ”‚ MODELED_DURATION       â”† Int64     â”† 61            â”‚\nâ”‚ COMPANY                â”† Int64     â”† 12303         â”‚\nâ”‚ COMPANY_NAME           â”† String    â”† 12302         â”‚\nâ”‚ COMPANY_RAW            â”† String    â”† 17214         â”‚\nâ”‚ COMPANY_IS_STAFFING    â”† Boolean   â”† 2             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nsome cleaning up first (round 1)â€¦\n\ncolumns_to_drop = [\n    'ID', 'URL', 'ACTIVE_URLS', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', \n    'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', \n    'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', \n    'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', \n    'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2', 'SOC_2_NAME', \n    'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', \n    'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', \n    'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME'\n]\n\njobs_filtered = jobs.drop(columns_to_drop)\n\nprint(jobs_filtered.columns)\n\n['LAST_UPDATED_DATE', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\njobs_filtered.shape\n\n(72476, 94)\n\n\n\nnan_counts = jobs_filtered.null_count()\n# looking at all columns\n\nnan_counts_long = nan_counts.unpivot().rename({\"variable\": \"Column\", \"value\": \"NaN Count\"})\n\nprint(nan_counts_long.shape)\n\n(94, 2)\n\n\n\nprint(nan_counts_long.head(20))\n\nshape: (20, 2)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Column                â”† NaN Count â”‚\nâ”‚ ---                   â”† ---       â”‚\nâ”‚ str                   â”† u32       â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ LAST_UPDATED_DATE     â”† 0         â”‚\nâ”‚ POSTED                â”† 0         â”‚\nâ”‚ EXPIRED               â”† 7822      â”‚\nâ”‚ DURATION              â”† 27294     â”‚\nâ”‚ SOURCE_TYPES          â”† 0         â”‚\nâ”‚ â€¦                     â”† â€¦         â”‚\nâ”‚ EDUCATION_LEVELS      â”† 0         â”‚\nâ”‚ EDUCATION_LEVELS_NAME â”† 0         â”‚\nâ”‚ MIN_EDULEVELS         â”† 0         â”‚\nâ”‚ MIN_EDULEVELS_NAME    â”† 0         â”‚\nâ”‚ MAX_EDULEVELS         â”† 56155     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n# testing the msno heatmap\n\njobs_filtered_pd = jobs_filtered.to_pandas()\n\nmsno.heatmap(jobs_filtered_pd)\n\n\n\n\n\n\n\n\n\n# showing only columns with NaN values\n\nnan_counts = jobs_filtered.null_count()\ntotal_rows = jobs_filtered.height\n\nnan_counts_filtered = (\n    nan_counts.unpivot()\n    .rename({\"variable\": \"Column\", \"value\": \"NaN Count\"})\n    .filter(pl.col(\"NaN Count\") &gt; 0)\n    .with_columns(\n        (pl.col(\"NaN Count\") / total_rows * 100).alias(\"NaN Percentage\")\n    )\n)\n\nprint(nan_counts_filtered.to_pandas())\n\n                    Column  NaN Count  NaN Percentage\n0                  EXPIRED       7822       10.792538\n1                 DURATION      27294       37.659363\n2      ACTIVE_SOURCES_INFO      64654       89.207462\n3                TITLE_RAW         60        0.082786\n4          MODELED_EXPIRED      15383       21.224957\n5         MODELED_DURATION      19261       26.575694\n6              COMPANY_RAW        497        0.685744\n7            MAX_EDULEVELS      56155       77.480821\n8       MAX_EDULEVELS_NAME      56155       77.480821\n9     MIN_YEARS_EXPERIENCE      23113       31.890557\n10    MAX_YEARS_EXPERIENCE      64046       88.368563\n11                  SALARY      41658       57.478338\n12     ORIGINAL_PAY_PERIOD      40068       55.284508\n13               SALARY_TO      40068       55.284508\n14             SALARY_FROM      40068       55.284508\n15                     MSA       3908        5.392130\n16                MSA_NAME       3908        5.392130\n17            MSA_OUTGOING       3908        5.392130\n18       MSA_NAME_OUTGOING       3908        5.392130\n19            MSA_INCOMING       3921        5.410067\n20       MSA_NAME_INCOMING       3921        5.410067\n21             TITLE_CLEAN         96        0.132458\n22       LIGHTCAST_SECTORS      54682       75.448424\n23  LIGHTCAST_SECTORS_NAME      54682       75.448424\n\n\n\n# visualize\n\nnan_counts_filtered_pd = nan_counts_filtered.to_pandas()\n\nfig = px.bar(\n    nan_counts_filtered_pd,\n    x=\"Column\",\n    y=\"NaN Percentage\",\n    color=\"NaN Percentage\",\n    title=\"NaN Percentages per Column\",\n    color_continuous_scale=\"Viridis\"\n)\n\nfig.update_layout(width=1200, height=500, xaxis_tickangle=-45)\nfig.show()\n\n                                                \n\n\na bit more cleaning up (round 2)â€¦\n\n# removing columns comprised of 50% or higher NaN values (except SALARY, SALARY_FROM, SALARY_TO)\n\ncolumns_to_drop = [\n    \"ACTIVE_SOURCES_INFO\", \"MAX_EDULEVELS\", \"MAX_EDULEVELS_NAME\", \"MAX_YEARS_EXPERIENCE\", \n    \"ORIGINAL_PAY_PERIOD\", \"LIGHTCAST_SECTORS\", \"LIGHTCAST_SECTORS_NAME\"\n]\n\njobs_filtered_2 = jobs_filtered.drop(columns_to_drop)\n\n\nprint(jobs_filtered_2.shape)\n\n(72476, 87)\n\n\n\n# and also remove duplicates\n\njobs_filtered_2 = jobs_filtered_2.unique(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nprint(jobs_filtered_2.shape)\n\n(69200, 87)\n\n\n\nnan_counts = jobs_filtered_2.null_count()\ntotal_rows = jobs_filtered_2.height \n\nnan_counts_filtered = (\n    nan_counts.unpivot()\n    .rename({\"variable\": \"Column\", \"value\": \"NaN Count\"})\n    .filter(pl.col(\"NaN Count\") &gt; 0)  \n    .with_columns(\n        (pl.col(\"NaN Count\") / total_rows * 100).alias(\"NaN Percentage\")\n    )\n)\n\nprint(nan_counts_filtered.to_pandas())\n\n                  Column  NaN Count  NaN Percentage\n0                EXPIRED       7462       10.783237\n1               DURATION      26092       37.705202\n2              TITLE_RAW         54        0.078035\n3        MODELED_EXPIRED      14739       21.299133\n4       MODELED_DURATION      18401       26.591040\n5            COMPANY_RAW        489        0.706647\n6   MIN_YEARS_EXPERIENCE      22339       32.281792\n7                 SALARY      39954       57.736994\n8              SALARY_TO      38490       55.621387\n9            SALARY_FROM      38490       55.621387\n10                   MSA       2806        4.054913\n11              MSA_NAME       2806        4.054913\n12          MSA_OUTGOING       2806        4.054913\n13     MSA_NAME_OUTGOING       2806        4.054913\n14          MSA_INCOMING       2816        4.069364\n15     MSA_NAME_INCOMING       2816        4.069364\n16           TITLE_CLEAN         88        0.127168\n\n\n\n# insight into remote jobs\n\nremote_type_series = jobs_filtered_2.get_column(\"REMOTE_TYPE_NAME\")\n\nvalue_counts = remote_type_series.value_counts(sort=True)\n\nprint(value_counts)\n\nshape: (4, 2)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ REMOTE_TYPE_NAME â”† count â”‚\nâ”‚ ---              â”† ---   â”‚\nâ”‚ str              â”† u32   â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\nâ”‚ [None]           â”† 54211 â”‚\nâ”‚ Remote           â”† 11745 â”‚\nâ”‚ Hybrid Remote    â”† 2151  â”‚\nâ”‚ Not Remote       â”† 1093  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\ngo ahead with a SQL connectionâ€¦\n\nconn = sqlite3.connect(':memory:')\n\nconn.execute(\"DROP TABLE IF EXISTS jobs;\")\n\ncolumns = \", \".join([f\"{col} TEXT\" for col in jobs_filtered_2.columns])\ncreate_table_query = f\"CREATE TABLE jobs ({columns});\"\nconn.execute(create_table_query)\n\ninsert_query = f\"INSERT INTO jobs VALUES ({', '.join(['?'] * len(jobs_filtered_2.columns))})\"\n\nconn.executemany(insert_query, jobs_filtered_2.to_numpy().tolist())\n\nconn.commit()\n\nprint(\"Data from jobs_filtered_2 has been successfully inserted into the SQLite database.\")\n\nData from jobs_filtered_2 has been successfully inserted into the SQLite database.\n\n\n\nquery_count = \"\"\"\nSELECT COUNT(*) AS TotalCount\nFROM jobs;\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_count)\nresult = cursor.fetchall()\n\ntotal_count = pl.DataFrame(result, schema=[\"TotalCount\"])\n\nprint(total_count)\n\nshape: (1, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TotalCount â”‚\nâ”‚ ---        â”‚\nâ”‚ i64        â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 69200      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nby NAICS_2022_6_NAME\n\nunique_naics_count = jobs_filtered_2.select(pl.col(\"NAICS_2022_6_NAME\").n_unique()).to_numpy()\n\nprint(f\"Unique NAICS_2022_6_NAME count: {unique_naics_count[0][0]}\")\n\nUnique NAICS_2022_6_NAME count: 814\n\n\n\n# We're interseted in the finance, marketing, and transportation industries\n\nquery_filtered_naics_count = \"\"\"\nSELECT COUNT(DISTINCT NAICS_2022_6_NAME) AS Unique_NAICS_Count\nFROM jobs\nWHERE NAICS_2022_6_NAME LIKE '%finance%'\n   OR NAICS_2022_6_NAME LIKE '%banking%'\n   OR NAICS_2022_6_NAME LIKE '%investing%'\n   OR NAICS_2022_6_NAME LIKE '%investments%'\n   OR NAICS_2022_6_NAME LIKE '%marketing%'\n   OR NAICS_2022_6_NAME LIKE '%transportation%';\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_filtered_naics_count)\nresult = cursor.fetchall()\n\nunique_filtered_naics_count_df = pl.DataFrame(result, schema=[\"Unique_NAICS_Count\"])\n\nprint(unique_filtered_naics_count_df)\n\nshape: (1, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Unique_NAICS_Count â”‚\nâ”‚ ---                â”‚\nâ”‚ i64                â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ 28                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\npl.Config.set_tbl_rows(28)  \n\nquery_filtered_naics = \"\"\"\nSELECT DISTINCT NAICS_2022_6_NAME\nFROM jobs\nWHERE NAICS_2022_6_NAME LIKE '%finance%'\n   OR NAICS_2022_6_NAME LIKE '%banking%'\n   OR NAICS_2022_6_NAME LIKE '%investing%'\n   OR NAICS_2022_6_NAME LIKE '%investments%'\n   OR NAICS_2022_6_NAME LIKE '%marketing%'\n   OR NAICS_2022_6_NAME LIKE '%transportation%';\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_filtered_naics)\nresult = cursor.fetchall()\n\nfiltered_naics_df = pl.DataFrame(result, schema=[\"NAICS_2022_6_NAME\"], orient=\"row\")\n\nprint(filtered_naics_df.shape)\n\n(28, 1)\n\n\n\nprint(filtered_naics_df)\n\nshape: (28, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ NAICS_2022_6_NAME               â”‚\nâ”‚ ---                             â”‚\nâ”‚ str                             â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Commercial Banking              â”‚\nâ”‚ Scheduled Passenger Air Transpâ€¦ â”‚\nâ”‚ Telemarketing Bureaus and Otheâ€¦ â”‚\nâ”‚ Investment Banking and Securitâ€¦ â”‚\nâ”‚ Marketing Consulting Services   â”‚\nâ”‚ Freight Transportation Arrangeâ€¦ â”‚\nâ”‚ Regulation of Agricultural Marâ€¦ â”‚\nâ”‚ Marketing Research and Public â€¦ â”‚\nâ”‚ Special Needs Transportation    â”‚\nâ”‚ Regulation and Administration â€¦ â”‚\nâ”‚ Nonscheduled Chartered Freightâ€¦ â”‚\nâ”‚ Scenic and Sightseeing Transpoâ€¦ â”‚\nâ”‚ Other Support Activities for Aâ€¦ â”‚\nâ”‚ Public Finance Activities       â”‚\nâ”‚ Nonscheduled Chartered Passengâ€¦ â”‚\nâ”‚ Pipeline Transportation of Natâ€¦ â”‚\nâ”‚ School and Employee Bus Transpâ€¦ â”‚\nâ”‚ Scheduled Freight Air Transporâ€¦ â”‚\nâ”‚ Pipeline Transportation of Cruâ€¦ â”‚\nâ”‚ All Other Pipeline Transportatâ€¦ â”‚\nâ”‚ Inland Water Freight Transportâ€¦ â”‚\nâ”‚ Deep Sea Freight Transportatioâ€¦ â”‚\nâ”‚ All Other Transit and Ground Pâ€¦ â”‚\nâ”‚ Pipeline Transportation of Refâ€¦ â”‚\nâ”‚ Transportation Equipment and Sâ€¦ â”‚\nâ”‚ Support Activities for Rail Trâ€¦ â”‚\nâ”‚ All Other Transportation Equipâ€¦ â”‚\nâ”‚ Other Support Activities for Râ€¦ â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n#drop any filtered NAICS_2022_6_NAME(s) without salary information\n\nquery_avg_salary_by_filtered_naics = \"\"\"\nSELECT \n    NAICS_2022_6_NAME,\n    COUNT(NAICS_2022_6_NAME) AS Occurrences,\n    AVG(SALARY) AS Avg_Salary,\n    AVG(SALARY_FROM) AS Avg_Salary_From,\n    AVG(SALARY_TO) AS Avg_Salary_To\nFROM jobs\nWHERE SALARY IS NOT NULL AND SALARY_TO IS NOT NULL AND SALARY_FROM IS NOT NULL\n  AND (NAICS_2022_6_NAME LIKE '%finance%'\n   OR NAICS_2022_6_NAME LIKE '%banking%'\n   OR NAICS_2022_6_NAME LIKE '%investing%'\n   OR NAICS_2022_6_NAME LIKE '%investments%'\n   OR NAICS_2022_6_NAME LIKE '%marketing%'\n   OR NAICS_2022_6_NAME LIKE '%transportation%')\nGROUP BY NAICS_2022_6_NAME\nORDER BY Occurrences DESC;\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_avg_salary_by_filtered_naics)\nresult = cursor.fetchall()\n\npl.Config.set_tbl_rows(28) \npl.Config.set_tbl_cols(None) \n\navg_salary_by_filtered_naics_df = pl.DataFrame(result, schema=[\"NAICS_2022_6_NAME\", \"Occurrences\", \"Avg_Salary\", \"Avg_Salary_From\", \"Avg_Salary_To\"], orient=\"row\")\n\nprint(avg_salary_by_filtered_naics_df.shape)\n\n(23, 5)\n\n\n\n# NOTE: drops 5\n\nprint(avg_salary_by_filtered_naics_df)\n\nshape: (23, 5)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ NAICS_2022_6_NAME               â”† Occurrences â”† Avg_Salary    â”† Avg_Salary_From â”† Avg_Salary_To â”‚\nâ”‚ ---                             â”† ---         â”† ---           â”† ---             â”† ---           â”‚\nâ”‚ str                             â”† i64         â”† f64           â”† f64             â”† f64           â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Commercial Banking              â”† 922         â”† 127314.572668 â”† 103130.91757    â”† 151398.733189 â”‚\nâ”‚ Telemarketing Bureaus and Otheâ€¦ â”† 201         â”† 90259.129353  â”† 72430.199005    â”† 107765.024876 â”‚\nâ”‚ Investment Banking and Securitâ€¦ â”† 94          â”† 120806.776596 â”† 95981.223404    â”† 144876.382979 â”‚\nâ”‚ Marketing Consulting Services   â”† 48          â”† 79475.604167  â”† 69490.916667    â”† 87989.833333  â”‚\nâ”‚ Regulation and Administration â€¦ â”† 28          â”† 93925.928571  â”† 76147.75        â”† 111066.857143 â”‚\nâ”‚ Scheduled Passenger Air Transpâ€¦ â”† 18          â”† 121229.555556 â”† 105449.777778   â”† 137009.444444 â”‚\nâ”‚ Marketing Research and Public â€¦ â”† 14          â”† 90237.857143  â”† 73339.285714    â”† 107136.428571 â”‚\nâ”‚ Public Finance Activities       â”† 13          â”† 108434.923077 â”† 85725.0         â”† 131145.153846 â”‚\nâ”‚ Regulation of Agricultural Marâ€¦ â”† 11          â”† 85541.909091  â”† 73135.454545    â”† 97948.636364  â”‚\nâ”‚ Freight Transportation Arrangeâ€¦ â”† 10          â”† 79420.3       â”† 70311.1         â”† 88529.8       â”‚\nâ”‚ Other Support Activities for Aâ€¦ â”† 6           â”† 82500.0       â”† 71333.333333    â”† 93666.666667  â”‚\nâ”‚ Nonscheduled Chartered Freightâ€¦ â”† 6           â”† 108785.333333 â”† 91843.166667    â”† 125727.666667 â”‚\nâ”‚ Pipeline Transportation of Natâ€¦ â”† 3           â”† 98722.666667  â”† 76333.333333    â”† 120000.0      â”‚\nâ”‚ Special Needs Transportation    â”† 2           â”† 62565.5       â”† 57566.0         â”† 65286.5       â”‚\nâ”‚ School and Employee Bus Transpâ€¦ â”† 2           â”† 62650.0       â”† 61090.0         â”† 64210.0       â”‚\nâ”‚ Scenic and Sightseeing Transpoâ€¦ â”† 2           â”† 80069.5       â”† 67591.0         â”† 92548.0       â”‚\nâ”‚ All Other Transit and Ground Pâ€¦ â”† 2           â”† 90675.0       â”† 77500.0         â”† 103850.0      â”‚\nâ”‚ Support Activities for Rail Trâ€¦ â”† 1           â”† 150000.0      â”† 140000.0        â”† 160000.0      â”‚\nâ”‚ Scheduled Freight Air Transporâ€¦ â”† 1           â”† 62400.0       â”† 62400.0         â”† 62400.0       â”‚\nâ”‚ Other Support Activities for Râ€¦ â”† 1           â”† 55000.0       â”† 50000.0         â”† 60000.0       â”‚\nâ”‚ Nonscheduled Chartered Passengâ€¦ â”† 1           â”† 47008.0       â”† 47008.0         â”† 47008.0       â”‚\nâ”‚ Deep Sea Freight Transportatioâ€¦ â”† 1           â”† 131400.0      â”† 111300.0        â”† 151500.0      â”‚\nâ”‚ All Other Transportation Equipâ€¦ â”† 1           â”† 89523.0       â”† 73299.0         â”† 105747.0      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nby TITLE_NAME\n\nunique_title_count = jobs_filtered_2.select(pl.col(\"TITLE_NAME\").n_unique()).to_numpy()\n\nprint(f\"Unique TITLE_NAME count: {unique_title_count[0][0]}\")\n\nUnique TITLE_NAME count: 5720\n\n\n\n# We're interested in analyst positions\n\npl.Config.set_tbl_rows(5000)\n\nquery_filtered_title = \"\"\"\nSELECT DISTINCT TITLE_NAME\nFROM jobs\nWHERE TITLE_NAME LIKE '%analyst%'\n   OR TITLE_NAME LIKE '%analytics%'\n   OR TITLE_NAME LIKE '%data%';\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_filtered_title)\nresult = cursor.fetchall()\n\nfiltered_title_df = pl.DataFrame(result, schema=[\"TITLE_NAME\"], orient=\"row\")\n\nprint(filtered_title_df.shape)\n\n(1476, 1)\n\n\n\nprint(filtered_title_df.head(20))\n\nshape: (20, 1)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TITLE_NAME                     â”‚\nâ”‚ ---                            â”‚\nâ”‚ str                            â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Data Analysts                  â”‚\nâ”‚ Oracle Analysts                â”‚\nâ”‚ Data Reporting Analysts        â”‚\nâ”‚ Data Management Analysts       â”‚\nâ”‚ Health Data Analysts           â”‚\nâ”‚ Lead Data Analysts             â”‚\nâ”‚ Customer Experience Analysts   â”‚\nâ”‚ Data Analytics Leads           â”‚\nâ”‚ WFM Analysts                   â”‚\nâ”‚ ERP Business Analysts          â”‚\nâ”‚ Business Intelligence Analysts â”‚\nâ”‚ Oracle Database Administrators â”‚\nâ”‚ Oracle Functional Analysts     â”‚\nâ”‚ Principal Data Scientists      â”‚\nâ”‚ Oracle Programmer Analysts     â”‚\nâ”‚ Enterprise Data Architects     â”‚\nâ”‚ Data and Reporting Analysts    â”‚\nâ”‚ ERP Systems Analysts           â”‚\nâ”‚ SAP Functional Analysts        â”‚\nâ”‚ Fraud Analysts                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n\n#drop any filtered TITLE_NAMES(s) without salary information\n\nquery_avg_salary_by_filtered_title = \"\"\"\nSELECT \n    TITLE_NAME,\n    COUNT(TITLE_NAME) AS Occurrences,\n    AVG(SALARY) AS Avg_Salary,\n    AVG(SALARY_FROM) AS Avg_Salary_From,\n    AVG(SALARY_TO) AS Avg_Salary_To\nFROM jobs\nWHERE SALARY IS NOT NULL AND SALARY_TO IS NOT NULL AND SALARY_FROM IS NOT NULL\n  AND (TITLE_NAME LIKE '%analyst%'\n   OR TITLE_NAME LIKE '%analytics%'\n   OR TITLE_NAME LIKE '%data%')\nGROUP BY TITLE_NAME\nORDER BY Occurrences DESC;\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_avg_salary_by_filtered_title)\nresult = cursor.fetchall()\n\npl.Config.set_tbl_rows(1500) \npl.Config.set_tbl_cols(None) \n\navg_salary_by_filtered_title_df = pl.DataFrame(result, schema=[\"TITLE_NAME\", \"Occurrences\", \"Avg_Salary\", \"Avg_Salary_From\", \"Avg_Salary_To\"], orient=\"row\")\n\nprint(avg_salary_by_filtered_title_df.shape)\n\n(1005, 5)\n\n\n\n# NOTE: drops 471\n\nprint(avg_salary_by_filtered_title_df.head(20))\n\nshape: (20, 5)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TITLE_NAME                      â”† Occurrences â”† Avg_Salary    â”† Avg_Salary_From â”† Avg_Salary_To â”‚\nâ”‚ ---                             â”† ---         â”† ---           â”† ---             â”† ---           â”‚\nâ”‚ str                             â”† i64         â”† f64           â”† f64             â”† f64           â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Data Analysts                   â”† 3467        â”† 93825.56533   â”† 81035.9152      â”† 106047.649841 â”‚\nâ”‚ Business Intelligence Analysts  â”† 938         â”† 103024.716418 â”† 87234.638593    â”† 118629.098081 â”‚\nâ”‚ Data Analytics Engineers        â”† 325         â”† 185512.461538 â”† 161054.243077   â”† 209111.68     â”‚\nâ”‚ Data and Reporting Analysts     â”† 290         â”† 79633.92069   â”† 66126.458621    â”† 91923.089655  â”‚\nâ”‚ Data Governance Analysts        â”† 228         â”† 111827.557018 â”† 94360.548246    â”† 128478.942982 â”‚\nâ”‚ Data Quality Analysts           â”† 193         â”† 104164.165803 â”† 91157.621762    â”† 116710.108808 â”‚\nâ”‚ Data Analytics Analysts         â”† 192         â”† 109418.296875 â”† 87121.588542    â”† 131655.473958 â”‚\nâ”‚ Data Management Analysts        â”† 178         â”† 107976.398876 â”† 92009.02809     â”† 123313.651685 â”‚\nâ”‚ Data Modelers                   â”† 172         â”† 136975.895349 â”† 118876.593023   â”† 155075.238372 â”‚\nâ”‚ Lead Data Analysts              â”† 170         â”† 111721.929412 â”† 95335.964706    â”† 127742.011765 â”‚\nâ”‚ Research Data Analysts          â”† 166         â”† 81899.710843  â”† 69225.656627    â”† 94308.771084  â”‚\nâ”‚ IT Data Analytics Analysts      â”† 164         â”† 107843.939024 â”† 84157.25        â”† 131339.04878  â”‚\nâ”‚ Lead Business Intelligence Anaâ€¦ â”† 151         â”† 120744.960265 â”† 100244.437086   â”† 140527.245033 â”‚\nâ”‚ Data Science Analysts           â”† 133         â”† 114863.992481 â”† 96807.609023    â”† 132389.849624 â”‚\nâ”‚ Data Analytics Leads            â”† 120         â”† 162420.35     â”† 120716.908333   â”† 203772.808333 â”‚\nâ”‚ Data Operations Analysts        â”† 114         â”† 88823.359649  â”† 73918.745614    â”† 102379.657895 â”‚\nâ”‚ Business Intelligence Data Anaâ€¦ â”† 113         â”† 103099.938053 â”† 87012.858407    â”† 119073.752212 â”‚\nâ”‚ Health Data Analysts            â”† 107         â”† 91458.654206  â”† 74872.214953    â”† 107990.401869 â”‚\nâ”‚ Data and Analytics Consultants  â”† 107         â”† 127020.224299 â”† 94460.691589    â”† 158536.672897 â”‚\nâ”‚ Enterprise Data Architects      â”† 106         â”† 166127.603774 â”† 146011.613208   â”† 186243.622642 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nnow use both of the queriesâ€¦\n\n# Analyst positions within the Industries we're interested in\n\nquery_avg_salary_by_filtered_title_naics = \"\"\"\nSELECT \n    TITLE_NAME,\n    NAICS_2022_6_NAME,\n    COUNT(TITLE_NAME) AS Occurrences,\n    AVG(SALARY) AS Avg_Salary,\n    AVG(SALARY_FROM) AS Avg_Salary_From,\n    AVG(SALARY_TO) AS Avg_Salary_To\nFROM jobs\nWHERE SALARY IS NOT NULL AND SALARY_TO IS NOT NULL AND SALARY_FROM IS NOT NULL\n  AND (TITLE_NAME LIKE '%analyst%'\n   OR TITLE_NAME LIKE '%analytics%'\n   OR TITLE_NAME LIKE '%data%')\n  AND (NAICS_2022_6_NAME LIKE '%finance%'\n   OR NAICS_2022_6_NAME LIKE '%banking%'\n   OR NAICS_2022_6_NAME LIKE '%investing%'\n   OR NAICS_2022_6_NAME LIKE '%investments%'\n   OR NAICS_2022_6_NAME LIKE '%marketing%'\n   OR NAICS_2022_6_NAME LIKE '%transportation%')\nGROUP BY TITLE_NAME, NAICS_2022_6_NAME\nORDER BY Occurrences DESC;\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_avg_salary_by_filtered_title_naics)\nresult = cursor.fetchall()\n\npl.Config.set_tbl_rows(250) \npl.Config.set_tbl_cols(None) \n\navg_salary_by_filtered_title_naics_df = pl.DataFrame(result, schema=[\"TITLE_NAME\", \"NAICS_2022_6_NAME\", \"Occurrences\", \"Avg_Salary\", \"Avg_Salary_From\", \"Avg_Salary_To\"], orient=\"row\")\n\nprint(avg_salary_by_filtered_title_naics_df.shape)\n\n(244, 6)\n\n\n\n# 244 remaining\n\nprint(avg_salary_by_filtered_title_naics_df.head(20))\n\nshape: (20, 6)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TITLE_NAME      â”† NAICS_2022_6_NA â”† Occurrences â”† Avg_Salary    â”† Avg_Salary_Fro â”† Avg_Salary_To â”‚\nâ”‚ ---             â”† ME              â”† ---         â”† ---           â”† m              â”† ---           â”‚\nâ”‚ str             â”† ---             â”† i64         â”† f64           â”† ---            â”† f64           â”‚\nâ”‚                 â”† str             â”†             â”†               â”† f64            â”†               â”‚\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\nâ”‚ Data and        â”† Telemarketing   â”† 65          â”† 81366.523077  â”† 64625.384615   â”† 97198.0       â”‚\nâ”‚ Reporting       â”† Bureaus and     â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysts        â”† Otheâ€¦           â”†             â”†               â”†                â”†               â”‚\nâ”‚ Health Data     â”† Telemarketing   â”† 51          â”† 94717.647059  â”† 75764.705882   â”† 113670.588235 â”‚\nâ”‚ Analysts        â”† Bureaus and     â”†             â”†               â”†                â”†               â”‚\nâ”‚                 â”† Otheâ€¦           â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data            â”† Commercial      â”† 41          â”† 172009.756098 â”† 137607.804878  â”† 206411.707317 â”‚\nâ”‚ Integration     â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Leads           â”†                 â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Governance â”† Commercial      â”† 35          â”† 129052.342857 â”† 103377.371429  â”† 154727.314286 â”‚\nâ”‚ Analysts        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Analysts   â”† Commercial      â”† 31          â”† 105933.612903 â”† 87030.903226   â”† 124547.258065 â”‚\nâ”‚                 â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Crime Analysts  â”† Telemarketing   â”† 25          â”† 46635.28      â”† 44214.4        â”† 48977.6       â”‚\nâ”‚                 â”† Bureaus and     â”†             â”†               â”†                â”†               â”‚\nâ”‚                 â”† Otheâ€¦           â”†             â”†               â”†                â”†               â”‚\nâ”‚ Lead Business   â”† Commercial      â”† 23          â”† 113100.0      â”† 86840.0        â”† 139360.0      â”‚\nâ”‚ Intelligence    â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Anaâ€¦            â”†                 â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Management â”† Commercial      â”† 20          â”† 159859.65     â”† 124353.0       â”† 195366.3      â”‚\nâ”‚ Analysts        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Business        â”† Commercial      â”† 19          â”† 109138.526316 â”† 88355.842105   â”† 129921.210526 â”‚\nâ”‚ Intelligence    â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysts        â”†                 â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Quality    â”† Commercial      â”† 17          â”† 107957.117647 â”† 85142.588235   â”† 130771.705882 â”‚\nâ”‚ Analysts        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Analytics  â”† Commercial      â”† 16          â”† 167973.3125   â”† 134563.0       â”† 201383.625    â”‚\nâ”‚ Leads           â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Enterprise Risk â”† Commercial      â”† 16          â”† 108521.25     â”† 81160.4375     â”† 135528.6875   â”‚\nâ”‚ Analysts        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Analysts   â”† Regulation and  â”† 14          â”† 93407.285714  â”† 73797.285714   â”† 113018.285714 â”‚\nâ”‚                 â”† Administration  â”†             â”†               â”†                â”†               â”‚\nâ”‚                 â”† â€¦               â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Warehouse  â”† Commercial      â”† 14          â”† 86984.714286  â”† 66977.0        â”† 106312.0      â”‚\nâ”‚ Business        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysâ€¦         â”†                 â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Quality    â”† Commercial      â”† 13          â”† 156542.230769 â”† 129509.615385  â”† 183574.846154 â”‚\nâ”‚ Leads           â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Business        â”† Investment      â”† 12          â”† 125392.5      â”† 92790.75       â”† 157995.0      â”‚\nâ”‚ Intelligence    â”† Banking and     â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysts        â”† Securitâ€¦        â”†             â”†               â”†                â”†               â”‚\nâ”‚ Business        â”† Telemarketing   â”† 11          â”† 107000.0      â”† 84927.272727   â”† 129072.727273 â”‚\nâ”‚ Intelligence    â”† Bureaus and     â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysts        â”† Otheâ€¦           â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Analysts   â”† Investment      â”† 10          â”† 82393.0       â”† 70166.0        â”† 94620.0       â”‚\nâ”‚                 â”† Banking and     â”†             â”†               â”†                â”†               â”‚\nâ”‚                 â”† Securitâ€¦        â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data Analytics  â”† Commercial      â”† 10          â”† 101205.0      â”† 88850.8        â”† 113559.2      â”‚\nâ”‚ Analysts        â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Data            â”† Commercial      â”† 10          â”† 115110.0      â”† 92377.0        â”† 137843.0      â”‚\nâ”‚ Integration     â”† Banking         â”†             â”†               â”†                â”†               â”‚\nâ”‚ Analysts        â”†                 â”†             â”†               â”†                â”†               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\nplot 1\n\navg_salary_by_filtered_title_naics_df = pl.DataFrame(result, schema=[\"TITLE_NAME\", \"NAICS_2022_6_NAME\", \"Occurrences\", \"Avg_Salary\", \"Avg_Salary_From\", \"Avg_Salary_To\"], orient=\"row\")\n\navg_salary_by_filtered_title_naics_df_pd = avg_salary_by_filtered_title_naics_df.to_pandas()\n\ntop_20_df = avg_salary_by_filtered_title_naics_df_pd.head(20)\n\nfig = px.bar(top_20_df, \n             x='TITLE_NAME', \n             y='Occurrences', \n             color='NAICS_2022_6_NAME', \n             title=\"Top 20 Job Titles by Occurrences and their Industry with Applied Filters\",\n             labels={'TITLE_NAME': 'Job Title', 'Occurrences': 'Number of Occurrences'},\n             hover_data=['Avg_Salary', 'Avg_Salary_From', 'Avg_Salary_To'])\n\nfig.update_layout(xaxis_tickangle=45)\n\nfig.show()\n\n                                                \n\n\nplot 2\n\nquery_avg_salary_by_filtered_title_naics_state = \"\"\"\nSELECT \n    TITLE_NAME,\n    NAICS_2022_6_NAME,\n    STATE_NAME,\n    COUNT(TITLE_NAME) AS Occurrences,\n    AVG(SALARY) AS Avg_Salary,\n    AVG(SALARY_FROM) AS Avg_Salary_From,\n    AVG(SALARY_TO) AS Avg_Salary_To\nFROM jobs\nWHERE SALARY IS NOT NULL AND SALARY_TO IS NOT NULL AND SALARY_FROM IS NOT NULL\n  AND (TITLE_NAME LIKE '%analyst%'\n   OR TITLE_NAME LIKE '%analytics%'\n   OR TITLE_NAME LIKE '%data%')\n  AND (NAICS_2022_6_NAME LIKE '%finance%'\n   OR NAICS_2022_6_NAME LIKE '%banking%'\n   OR NAICS_2022_6_NAME LIKE '%investing%'\n   OR NAICS_2022_6_NAME LIKE '%investments%'\n   OR NAICS_2022_6_NAME LIKE '%marketing%'\n   OR NAICS_2022_6_NAME LIKE '%transportation%')\nGROUP BY STATE_NAME\nORDER BY Occurrences DESC\nLIMIT 7;\n\"\"\"\n\ncursor = conn.cursor()\ncursor.execute(query_avg_salary_by_filtered_title_naics_state)\nresult = cursor.fetchall()\n\npl.Config.set_tbl_rows(250) \npl.Config.set_tbl_cols(None)\n\navg_salary_by_filtered_title_naics_state_df = pl.DataFrame(result, schema=[\"TITLE_NAME\", \"NAICS_2022_6_NAME\", \"STATE_NAME\", \"Occurrences\", \"Avg_Salary\", \"Avg_Salary_From\", \"Avg_Salary_To\"], orient=\"row\")\n\navg_salary_by_filtered_title_naics_state_df_pd = avg_salary_by_filtered_title_naics_state_df.to_pandas()\n\n\nfig = px.pie(avg_salary_by_filtered_title_naics_state_df_pd,\n             names='STATE_NAME',\n             values='Occurrences',\n             title=\"Top 7 States by Occurrences with Applied Filters\",\n             color='STATE_NAME')\n\nfig.show()\n\n                                                \n\n\nplot 3\n\navg_salary_by_filtered_title_naics_df_pd = avg_salary_by_filtered_title_naics_df.to_pandas()\n\nfig = px.treemap(\n    avg_salary_by_filtered_title_naics_df_pd,\n    path=['NAICS_2022_6_NAME', 'TITLE_NAME'], \n    values='Occurrences',                      \n    color='Avg_Salary',                        \n    color_continuous_scale='Viridis',       \n    title='Analyst Positions within Selected Industries with Recorded Salary Information'\n)\n\nfig.update_layout(\n    margin=dict(t=50, l=25, r=25, b=25),\n    coloraxis_colorbar=dict(\n        title=\"Avg Salary\",\n        tickprefix=\"$\"\n    )\n)\n\nfig.show()\n\n                                                \n\n\n\nconn.close()"
  },
  {
    "objectID": "skills_gap_analysis.html",
    "href": "skills_gap_analysis.html",
    "title": "Business Running Case: Evaluating Personal Job Market Prospects in 2024",
    "section": "",
    "text": "Project Phase III\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.express as px\nimport plotly.io as pio\n\n\nimport plotly.io as pio\n\n# Set global theme for all Plotly plots\npio.templates.default = \"plotly_white\"\n\n\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\n\n/tmp/ipykernel_1659/3047231268.py:1: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\npd.set_option('display.max_columns', None) \npd.set_option('display.width', None)\n# df.head()\n\n\n#df.columns.tolist()\n\nCreating a Skill Level DataFrame\n\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Andrey\", \"Moiz\", \"Jason\", \"Prabu\",\"Jitvan\"],\n    \"Python (Programming Language)\": [5, 3, 4, 4, 2],\n    \"SQL (Programming Language)\": [4, 3, 5, 3, 5],\n    \"Microsoft Excel\": [3, 5, 4, 4, 4],\n    \"Power BI\": [2, 4, 3, 3, 5],\n    \"Tableau\": [3, 4, 3, 4, 3]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython (Programming Language)\nSQL (Programming Language)\nMicrosoft Excel\nPower BI\nTableau\n\n\nName\n\n\n\n\n\n\n\n\n\nAndrey\n5\n4\n3\n2\n3\n\n\nMoiz\n3\n3\n5\n4\n4\n\n\nJason\n4\n5\n4\n3\n3\n\n\nPrabu\n4\n3\n4\n3\n4\n\n\nJitvan\n2\n5\n4\n5\n3\n\n\n\n\n\n\n\n\nTeam Skill Insights\nFrom the matrix above, we observe:\n\nJason shows consistently strong proficiency across all listed tools, especially in SQL and Excel.\nJitvan excels in Power BI and SQL, but may benefit from further development in Python.\nMoiz demonstrates advanced proficiency in Excel and Tableau, indicating strong visualization and reporting capabilities.\nAndrey is an expert in Python but may require further training in Power BI.\nPrabu maintains intermediate-to-advanced competency across all tools, making him a well-rounded contributor.\n\n\n\nVisualizing Skill Gaps with Seaborn\n\n\nğŸ“Š Team Skill Levels â€“ Heatmap Analysis\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a mapping dictionary for display labels only\ncolumn_display_names = {\n    \"Python (Programming Language)\": \"Python\",\n    \"SQL (Programming Language)\": \"SQL\",\n    \"Microsoft Excel\": \"Excel\",\n    \"Power BI\": \"Power BI\",\n    \"Tableau\": \"Tableau\"\n}\n\nplt.figure(figsize=(10, 6))\nax = sns.heatmap(\n    df_skills,\n    annot=True,\n    cmap=\"coolwarm\",\n    linewidths=0.5,\n    linecolor='white',\n    cbar=True,\n    fmt='g'\n)\n\n# Set cleaned display names just for x-axis\nax.set_xticklabels([column_display_names.get(label, label) for label in df_skills.columns],\n                   rotation=0, ha='center', fontsize=10)\n\nplt.title(\"Team Skill Levels Heatmap\", fontsize=14)\nplt.yticks(rotation=0, fontsize=10)\nplt.tight_layout()\n\n# Save the figure\nplt.savefig(\"plots.qmd/Team_Skill_Levels_Heatmap.png\", dpi=300, bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\n\n\n\nThe heatmap above offers a visual overview of our teamâ€™s self-assessed proficiency across five core analytical tools: Python, SQL, Excel, Power BI, and Tableau. The color intensity reflects the skill level, with darker shades representing higher proficiency (scale: 1 = Beginner, 5 = Expert).\n\nğŸ” Key Insights:\n\nPython: Andrey stands out with expert-level skills (5), while Jitvan shows the lowest proficiency (2), indicating a potential area for development.\nSQL: Jason and Jitvan both score the highest (5), reflecting strong database querying capabilities, while others maintain intermediate competency.\nExcel: Moiz and Jason demonstrate the highest proficiency (5), useful for data wrangling and reporting.\nPower BI: Jitvan leads with a top score (5), suggesting strong data visualization capabilities; however, Andrey scores the lowest (2), indicating a potential gap.\nTableau: All team members cluster around the intermediate level (3â€“4), showing consistent yet improvable skills across the board.\n\nThis heatmap complements the earlier skill matrix by allowing a quick comparative glance, which is particularly helpful in identifying areas of individual strength and skill gaps that may benefit from team-wide upskilling initiatives.\n\n\n\nTop 5 In-Demand Software Skills in IT (Industry-Level)\n\nimport pandas as pd\nimport ast                                     \nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\n# Define the relevant skill columns\nskill_columns = [\"SOFTWARE_SKILLS_NAME\"]\n\n# Function to safely parse stringified lists\ndef extract_skills(row):\n    skills = []\n    for col in skill_columns:\n        if pd.notna(row.get(col)):\n            try:\n                skills += ast.literal_eval(row[col])\n            except Exception:\n                continue\n    return skills\n\n# Apply function across rows\nall_skills = df.apply(extract_skills, axis=1).explode().dropna()\n\n# Count frequency of each skill\ntop_skills = Counter(all_skills).most_common(5)\ntop_skills_df = pd.DataFrame(top_skills, columns=[\"Skill\", \"Frequency\"])\n\n\n# Save to CSV\ntop_skills_df.to_csv(\"top_skills.csv\", index=False)\n\n# Create Plotly bar chart with salmon color\nfig = px.bar(\n    top_skills_df,\n    x=\"Frequency\",\n    y=\"Skill\",\n    orientation='h',\n    title=\"Top 5 In-Demand IT Skills\",\n    color_discrete_sequence=[\"salmon\"]  # global color theme\n)\n\n# Update layout for consistency\nfig.update_layout(\n    title_font_size=18,\n    title_font_family=\"Arial\",\n    plot_bgcolor=\"white\",\n    paper_bgcolor=\"white\",\n    font=dict(size=12),\n    margin=dict(t=60, l=50, r=30, b=50),\n)\n\nplt.savefig(\"plots.qmd/Top_5_In_Demand_IT_Skills.png\", dpi=300, bbox_inches='tight')\n\n# Display chart\nfig.show()\n\n                            \n                                            \n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\nThe bar chart above highlights the top five most frequently requested software-related skills in IT job postings, based on the extracted data from the SOFTWARE_SKILLS_NAME column in the Lightcast dataset.\n\nObservations:\n\nSQL (Programming Language) ranks as the most in-demand skill across job postings, signaling its foundational importance in data querying and backend systems.\nMicrosoft Excel continues to be widely valued, especially in roles that demand reporting, data cleaning, and spreadsheet-based operations.\nPython (Programming Language), a critical skill for automation, data analysis, and machine learning, ranks third â€” affirming its strong market relevance.\nSAP Applications, often used in enterprise resource planning (ERP) and supply chain systems, indicates a demand for professionals with domain-specific technical expertise.\nDashboard skills, representing tools like Tableau, Power BI, and similar platforms, round out the top five â€” showcasing the need for data visualization and communication capabilities.\n\nThese findings serve as a benchmark for evaluating whether our teamâ€™s skill sets align with current industry expectations â€” and will help guide upskilling priorities in the subsequent gap analysis.\n\n\n\n\nTeam Skills vs.Â Top 5 In-Demand IT Skills (Mapped Heatmap)\n\n# Step 1: Load the top skills list\ntop_skill_names = top_skills_df[\"Skill\"].tolist()\n\n# Step 2: Manually map top skills to df_skills columns\nskill_alias = {\n    \"SQL (Programming Language)\": \"SQL (Programming Language)\",\n    \"Python (Programming Language)\": \"Python (Programming Language)\",\n    \"Microsoft Excel\": \"Microsoft Excel\",\n    \"Power BI\": \"Power BI\",\n    \"Tableau (Business Intelligence Software)\": \"Tableau\", \n    \"Dashboard\": \"Tableau\",  \n    \"SAP Applications\": \"SAP Applications\" \n}\n\n# Step 3: Map all top skills (no filtering yet)\nmapped_top_skills = [skill_alias.get(skill, skill) for skill in top_skill_names]\n\n# Step 4: Ensure all mapped columns exist in df_skills\nfor skill in mapped_top_skills:\n    if skill not in df_skills.columns:\n        df_skills[skill] = 0  \n\n# Step 5: Now align after adding all\ndf_skills_aligned = df_skills[mapped_top_skills]\n\n\n# Step 5: Align df_skills with the mapped top skills\ndf_skills_aligned = df_skills[mapped_top_skills]\n\n# Shorten long x-axis tick labels\nshortened_labels = {\n    \"SQL (Programming Language)\": \"SQL\",\n    \"Python (Programming Language)\": \"Python\",\n    \"Microsoft Excel\": \"Excel\",\n    \"SAP Applications\": \"SAP\",\n    \"Tableau\": \"Tableau\"\n}\ndf_skills_aligned = df_skills_aligned.rename(columns=shortened_labels)\n\n\nplt.figure(figsize=(12, 5))\nsns.heatmap(df_skills_aligned, annot=True, cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Team Skill Levels vs Top 5 In-Demand IT Skills (Mapped)\")\nplt.xticks(rotation=0, ha='center') \nplt.tight_layout()\n\nplt.savefig(\"plots.qmd/Team_Skills_Vs_Top_5_In_Dmeand_IT_Skills.png\", dpi=300, bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\n\n\n\nThis heatmap visualizes the alignment between our teamâ€™s current skill levels and the top 5 most frequently requested IT skills from job postings: SQL, Excel, Python, SAP, and Tableau.\n\nKey Observations:\n\nSAP Applications show a complete skills gap across the team â€” no member currently reports proficiency, indicating a strong potential area for upskilling based on industry demand.\nSQL and Excel are relatively well-covered, with multiple team members (e.g., Jason, Jitvan, Moiz) scoring between 4â€“5, reflecting strong database and spreadsheet competencies.\nPython remains an essential and in-demand skill. While most team members show intermediate-to-high proficiency, one member (Jitvan) has a lower score of 2, indicating a learning opportunity.\nTableau, frequently requested under the category â€œDashboardâ€, is evenly represented, with all members scoring between 3 and 4 â€” suggesting a consistent but improvable baseline.\n\n\n\nTakeaway:\nThis mapped heatmap offers a focused lens on how well our collective capabilities align with current market expectations. Notably, SAP stands out as an urgent area for learning, while ongoing refinement in Tableau and Python can further improve the teamâ€™s employability and project readiness.\n\n\n\n\nTOP 5 IN DEMAND SPECIALIZED SKILLS IN IT\n\n# Define the relevant skill columns\nskill_columns = [\"SPECIALIZED_SKILLS_NAME\"]\n\n# Function to safely parse stringified lists\ndef extract_skills(row):\n    skills = []\n    for col in skill_columns:\n        if pd.notna(row.get(col)):\n            try:\n                skills += ast.literal_eval(row[col])\n            except Exception:\n                continue\n    return skills\n\n# Apply function across rows\nall_skills = df.apply(extract_skills, axis=1).explode().dropna()\n\n# Count frequency of each skill\ntop_skills = Counter(all_skills).most_common(5)\ntop_skills_df = pd.DataFrame(top_skills, columns=[\"Skill\", \"Frequency\"])\n\n# Optional: Save to CSV\ntop_skills_df.to_csv(\"top_skills.csv\", index=False)\n\nfig = px.bar(\n    top_skills_df,\n    x=\"Frequency\",\n    y=\"Skill\",\n    orientation='h',\n    title=\"Top In-Demand SPECIALIZED SKILLS In IT\",\n    color_discrete_sequence=[\"salmon\"]\n)\n\n# Update layout to match the global theme\nfig.update_layout(\n    plot_bgcolor='white',\n    paper_bgcolor='white',\n    font=dict(size=14, family=\"Arial\"),\n    title_font=dict(size=18, family=\"Arial\", color=\"black\"),\n    margin=dict(t=50, l=100, r=30, b=50),\n    showlegend=False,\n    xaxis=dict(title='Frequency', gridcolor='lightgrey'),\n    yaxis=dict(title='Skill', gridcolor='lightgrey')\n)\n\nplt.savefig(\"plots.qmd/Top_In_Demand_SPECIALIZED_Skills.png\", dpi=300, bbox_inches='tight')\n\nfig.show()\n\n                            \n                                            \n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\nThe horizontal bar chart above identifies the five most sought-after specialized skills extracted from the SPECIALIZED_SKILLS_NAME column within the Lightcast job postings dataset. These reflect deeper domain-specific capabilities expected by employers across the IT sector.\n\nObservations:\n\nData Analysis emerged as the most frequently mentioned specialized skill, underlining its critical role in transforming raw information into actionable insights across industries.\nSQL (Programming Language) maintains its strong presence, reinforcing its dual role as both a software and specialized technical skill essential for data management and querying.\nComputer Science appears prominently, indicating employersâ€™ preference for candidates with a foundational understanding of algorithms, system architecture, and programming principles.\nProject Management ranks high, suggesting that beyond technical proficiency, employers are seeking professionals who can also manage timelines, deliverables, and stakeholder expectations effectively.\nBusiness Process knowledge also stands out, pointing to demand for skills that bridge technical solutions with operational efficiency.\n\n\n\nInterpretation:\nThese specialized skills reflect a blend of technical expertise and operational acumen. When compared to our teamâ€™s current skills, some gaps â€” such as Project Management, Business Process, and Data Analysis â€” may represent areas of opportunity for targeted learning and future curriculum alignment.\n\n\n\n\nTop In-Demand Common (Soft) Skills in IT\n\n# Define the relevant skill columns\nskill_columns = [\"COMMON_SKILLS_NAME\"]\n\n# Function to safely parse stringified lists\ndef extract_skills(row):\n    skills = []\n    for col in skill_columns:\n        if pd.notna(row.get(col)):\n            try:\n                skills += ast.literal_eval(row[col])\n            except Exception:\n                continue\n    return skills\n\n# Apply function across rows\nall_skills = df.apply(extract_skills, axis=1).explode().dropna()\n\n# Count frequency of each skill\ntop_skills = Counter(all_skills).most_common(5)\ntop_skills_df = pd.DataFrame(top_skills, columns=[\"Skill\", \"Frequency\"])\n\n# Optional: Save to CSV\ntop_skills_df.to_csv(\"top_skills.csv\", index=False)\n\n\n# Apply global theme\npio.templates.default = \"plotly_white\"\n\n# Plotly common skills chart with consistent layout\nfig = px.bar(\n    top_skills_df,\n    x=\"Frequency\",\n    y=\"Skill\",\n    orientation='h',\n    color_discrete_sequence=[\"salmon\"],\n    title=\"Top In-Demand COMMON SKILLS In IT\"\n)\n\nfig.update_layout(\n    yaxis=dict(autorange=\"reversed\"),\n    margin=dict(t=50, l=50, r=25, b=25),\n    xaxis_title=\"Frequency\",\n    yaxis_title=\"\"\n)\n\nplt.savefig(\"plots.qmd/Top_in_Demand_COMMON_Skills_IT.png\", dpi=300, bbox_inches='tight')\n\nfig.show()\n\n                            \n                                            \n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n**\nThe chart above showcases the top five most frequently listed common skills â€” often referred to as soft skills â€” based on the COMMON_SKILLS_NAME column in the job postings dataset. These are non-technical but highly valued in IT roles across all organizational levels.\n\nObservations:\n\nCommunication ranks highest, emphasizing the critical need for professionals who can clearly articulate ideas, collaborate effectively across teams, and convey technical findings to non-technical stakeholders.\nManagement and Leadership both appear in the top five, reflecting the industryâ€™s growing need for individuals who can not only execute tasks but also lead initiatives, manage teams, and drive strategic outcomes.\nProblem Solving is another top-listed trait, aligning with the complex, analytical nature of most IT roles where troubleshooting and innovative thinking are routine.\nOperations rounds out the list, suggesting a demand for process-oriented thinking, efficiency, and understanding of business workflows.\n\n\n\nInterpretation:\nWhile often overlooked in technical training, these soft skills are crucial differentiators in hiring decisions. Regardless of specialization (data science, software development, or project management), interpersonal and leadership abilities significantly enhance employability. This insight reinforces the importance of combining technical expertise with strong communication and organizational skills in both curriculum design and individual development plans.\n\n\n\n\nTop 5 In-Demand IT Skills by Category â€“ Treemap Visualization\n\nimport pandas as pd\nimport ast\nfrom collections import Counter\nimport plotly.express as px\n\n# Define relevant skill columns and their categories\nskill_sources = {\n    \"SPECIALIZED_SKILLS_NAME\": \"Specialized\",\n    \"COMMON_SKILLS_NAME\": \"Common\",\n    \"SOFTWARE_SKILLS_NAME\": \"Software\"\n}\n\n# Function to safely extract list-like strings\ndef extract_skills(df, column_name):\n    all_skills = []\n    for row in df[column_name].dropna():\n        try:\n            all_skills += ast.literal_eval(row)\n        except:\n            continue\n    return all_skills\n\n# Create a DataFrame to store top skills across categories\ntreemap_data = []\n\nfor col, category in skill_sources.items():\n    skills = extract_skills(df, col)\n    top_5 = Counter(skills).most_common(5)\n    for skill, freq in top_5:\n        treemap_data.append({\n            \"Skill\": skill,\n            \"Category\": category,\n            \"Frequency\": freq\n        })\n\n# Convert to DataFrame\ntreemap_df = pd.DataFrame(treemap_data)\n\n# Plot Treemap\n# Set global Plotly theme\npio.templates.default = \"plotly_white\"\n\n# Treemap plot\nfig = px.treemap(\n    treemap_df,\n    path=[\"Category\", \"Skill\"],\n    values=\"Frequency\",\n    color=\"Category\",\n    color_discrete_map={\n        \"Specialized\": \"mediumpurple\",\n        \"Common\": \"salmon\",\n        \"Software\": \"skyblue\"\n    },\n    title=\"Top 5 In-Demand IT Skills by Category\"\n)\n\n# Add margin and show legend\nfig.update_layout(\n    margin=dict(t=50, l=25, r=25, b=25),\n    legend_title_text=\"Skill Category\",\n    legend=dict(\n        traceorder=\"normal\",\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"center\",\n        x=0.5\n    )\n)\n\nplt.savefig(\"plots.qmd/Top_5_in_Demand_Skill_by_Category.png\", dpi=300, bbox_inches='tight')\n\nfig.show()\n\n                            \n                                            \n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\nThe treemap above presents a unified visual overview of the most in-demand IT skills, categorized into three primary groups: Common, Specialized, and Software. Each rectangleâ€™s size represents the relative frequency of that skill across job postings.\n\nCategory Breakdown:\n\nCommon Skills (orange):\n\nThis category dominates the overall space, with Communication and Management leading the way.\nOther prominent soft skills include Problem Solving, Leadership, and Operations, reinforcing the industryâ€™s continued emphasis on interpersonal and leadership competencies alongside technical abilities.\n\nSpecialized Skills (Mediumpurple):\n\nData Analysis and SQL (Programming Language) are top mentions, reflecting their value in strategic decision-making and backend infrastructure.\nSkills such as Computer Science, Project Management, and Business Process suggest a need for foundational technical understanding coupled with domain-specific operational insights.\n\nSoftware Skills (Skyblue):\n\nThese are tools and technologies actively used in IT workflows.\nSQL, Excel, and Python appear again here, reaffirming their dual presence as both specialized knowledge and hands-on tools.\nSAP Applications and Dashboard (referring to visualization platforms like Tableau and Power BI) reflect enterprise-level technical expectations.\n\n\n\n\nInterpretation:\nThis treemap effectively integrates the earlier bar charts into one cohesive view, allowing for quick comparative analysis across skill types. It visually reinforces the multi-dimensional expectations of IT professionals â€” who must blend communication, strategic insight, and software proficiency to meet market demands.\nAs we move toward building an improvement plan, this treemap helps prioritize upskilling areas based on both category-level and individual skill-level significance.\n\n\n\n\nProposing an Improvement Plan\n\n\nğŸ”¹ Andrey\n\nSkills to Prioritize Learning: Power BI, Tableau, SAP Applications\nCourses or Resources:\n\nMicrosoft Power BI Data Analyst\nIntroduction to Tableau â€“ UC Davis\nSAP Professional Fundamentals\n\nTeam Collaboration Suggestion:\n\nCan shadow Jason and Prabu on Excel reporting dashboards.\nOrganize peer-led walkthroughs with Moiz on Tableau once Moiz completes his course.\n\n\n\n\n\nğŸ”¹ Moiz\n\nSkills to Prioritize Learning: Python, Power BI, SAP Applications\nCourses or Resources:\n\nPython for Everybody â€“ University of Michigan\nPower BI for Beginners â€“ Microsoft\nBecoming an SAP Professional\n\nTeam Collaboration Suggestion:\n\nPair with Jason to co-develop a dashboard and improve Power BI skills.\nConduct weekly learning swaps with Jitvan to practice Python.\n\n\n\n\n\nğŸ”¹ Jason\n\nSkills to Prioritize Learning: Power BI, SAP Applications\nCourses or Resources:\n\nMicrosoft Power BI for Beginners\nSAP Technology Consultant â€“ SAP\n\nTeam Collaboration Suggestion:\n\nLead weekly recap sessions on SQL with teammates.\nPractice SAP module navigation with Moiz and Andrey after completing the course.\n\n\n\n\n\nğŸ”¹ Prabu\n\nSkills to Prioritize Learning: SAP Applications\nCourses or Resources:\n\nImplementing an SAP Solution\n\nTeam Collaboration Suggestion:\n\nLead a team-wide â€œSAP Sundayâ€ mini hackathon once a month for hands-on SAP tasks.\nAssist others in brushing up Python and Excel via peer mentoring.\n\n\n\n\n\nğŸ”¹ Jitvan\n\nSkills to Prioritize Learning: Python, Excel, Tableau\nCourses or Resources:\n\nCrash Course on Python â€“ Google\nExcel Skills for Business â€“ Macquarie University\nData Visualization with Tableau â€“ UC Davis\n\nTeam Collaboration Suggestion:\n\nCo-present Tableau project findings with Moiz to practice and receive feedback.\nSchedule weekly â€œcode & coffeeâ€ Python debugging sessions with the team.\n\n\n\n\n\nSummary Collaboration Ideas\n\nAssign a â€œSkill Championâ€ for each domain (e.g., SQL â€“ Jason, Tableau â€“ Moiz) to mentor others.\nImplement weekly 30-minute peer-learning check-ins.\nMaintain a shared Notion or Google Doc for learning progress, notes, and resources.\nHost monthly demo days to present completed mini-projects using new tools learned."
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Business Running Case: Evaluating Personal Job Market Prospects in 2024",
    "section": "",
    "text": "ğŸ“Œ Introduction\nIn this project, we analyzed the â€œlightcast_job_postings.csvâ€ dataset, which contains detailed job market information, including job titles, companies, locations, salaries, and various metadata. The dataset initially comprised 131 columns, offering a comprehensive view of job postings and associated attributes for evaluating personal job market prospects in 2024.\n\nimport pandas as pd\nimport plotly.express as px\nimport missingno as msno\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nimport us\n\n\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\n\n/tmp/ipykernel_4593/3047231268.py:1: DtypeWarning: Columns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(\"lightcast_job_postings.csv\")\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n9/6/2024\n2024-09-06 20:32:57.352 Z\n0.0\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n8/2/2024\n2024-08-02 17:08:58.838 Z\n0.0\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n9/6/2024\n2024-09-06 20:32:57.352 Z\n1.0\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n6/19/2024\n2024-06-19 07:00:00.000 Z\n0.0\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n\n\n5 rows Ã— 131 columns\n\n\n\n\nprint(df.shape)\n\n(72498, 131)\n\n\n\n\nğŸ“Œ Data Cleaning & Preprocessing\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\n\nTo prepare the dataset for analysis, we undertook a thorough data cleaning and preprocessing process, including:\n\nDropping Irrelevant Columns:\n\n\nWe removed columns that were either redundant or not relevant to our analysis. These included unique identifiers (ID), URLs of job postings (URL, ACTIVE_URLS), and columns providing less granular versions of NAICS and SOC codes (NAICS2, SOC_3, etc.).\nThe rationale for dropping these columns was to enhance data efficiency and clarity, reduce the dataset size, and focus on the most granular and meaningful data.\n\n\n# Visualize missing data\nmsno.heatmap(df)\n\n\n\n\n\n\n\n\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values safely\ndf[\"NAICS_2022_6\"] = df[\"NAICS_2022_6\"].fillna(df[\"NAICS_2022_6\"].median())\ndf[\"NAICS_2022_6_NAME\"] = df[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\")\n\n\nHandling Missing Values:\n\n\nAs seen in the heatmap above, it reveals that the columns ACTIVE_SOURCES_INFO, MODELED_DURATION, and MODELED_EXPIRED contain significant missing values, suggesting potential data collection or extraction issues. Notably, DURATION and EXPIRED exhibit a moderate positive correlation (0.5), indicating that longer job durations might influence missingness in related columns.\nAdditionally, ACTIVE_SOURCES_INFO shows a strong negative correlation with other variables, implying a pattern where missing data in this column might coincide with gaps in others.\nIn contrast, columns like MSA, MSA_NAME, and LIGHTCAST_SECTORS have no missing values, providing a reliable foundation for further analysis. Addressing missing data in correlated columns through targeted imputation can prevent bias and enhance the accuracy of our analysis.\n\n\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\nRemoving Duplicates:\n\n\nTo maintain unique job postings, duplicates were removed based on job title, company, location, and posting date.\nThis ensured that each job opportunity was only represented once, preventing skewed analysis results.\n\n\n\nImpact of Data Cleaning\nThe data cleaning process resulted in a more streamlined and manageable dataset, eliminating redundancy and potential inconsistencies. This step set the foundation for accurate and insightful analysis in the subsequent phases of the project."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Group 1 â€“ Business Running Case: Evaluating Personal Job Market Prospects in 2024",
    "section": "",
    "text": "Boston University Metropolitan College\nProfessor Nakul Padalkar\n\nBusiness Analytics, Data Science, and Machine Learning Trends\nRationale:\nFirstly, on behalf of all of us in Group 1 - welcome.\nAfter careful consideration, we have collectively chosen to focus our research efforts on Business Analytics, Data Science, and Machine Learning Trends. The primary motivation for selecting this topic is that, in the long run, a deeper understanding of these areas will significantly strengthen our professional expertise and career prospects. Among the various research options available, we believe this theme holds the greatest potential for long-term impact as we pursue careers in the business analytics and data science disciplines.\nOur goal is to conduct thorough and insightful research that provides a reliable understanding of the industryâ€™s landscape at large. As is outlined in the assignment description, we aim to explore the most in-demand skills, examine how job descriptions have evolved in recent years, identify the leading employers of both business analysts and data scientists, and to assess the career outlook of these roles.\nIf approached strategically, the exploration will serve as a valuable resource, providing knowledge we can revisit and build upon throughout our careers - even as the industry continues to evolve.\nSincerely,\nGroup 1\n\n\nLiterature Review: Data Science, Business Analytics, and Machine Learning Trends\n\n\nIntroduction\nThe demand for professionals in data science, business analytics, and machine learning (ML) has surged as organizations increasingly rely on data-driven decision-making. Based on recent research, the most sought-after skills in these fields can be categorized into technical (hard skills) and non-technical (soft skills).\n\n\nIn-Demand Skills for Data Science, Business Analytics, and ML Roles\nHard Skills\n\nHard skills remain a fundamental requirement for data science (Umamaheswaran et al., 2023), business analytics, and ML roles.\n\nKey technical competencies include:\n\nProgramming Languages: Python, R, SQL, and Java are among the most demanded languages, with Python being particularly crucial for ML and data analytics applications.\nBig Data and Cloud Technologies: Expertise in cloud platforms such as AWS, Azure, and Google Cloud, along with tools like Hadoop and Spark, is increasingly valuable.\nMachine Learning & AI: Knowledge of machine learning frameworks such as TensorFlow, PyTorch, and Keras, along with expertise in neural networks and deep learning, is becoming a core requirement for ML-based roles.\nData Management and Visualization: Business Intelligence (BI) tools such as Tableau, Power BI, and data warehousing techniques are critical for business analytics roles.\nMathematics & Statistics: A strong grasp of statistics, probability, and mathematical modeling is necessary for data-driven roles.\n\nSoft Skills\nWhile technical expertise is crucial (Musazade, N. (2022), employers also prioritize soft skills that enable professionals to apply their knowledge effectively:\n\nCommunication & Stakeholder Management: Business analytics professionals require strong communication skills to translate data-driven insights into actionable business strategies.\nProblem-Solving & Critical Thinking: Employers value candidates who can apply analytical thinking to solve complex business problems and optimize decision-making processes.\nTeamwork & Leadership: Collaborating across teams and managing projects efficiently are critical skills, particularly for leadership roles in data science and analytics.\n\nEvolving Skill Trends\nThe increasing integration of machine learning in business analytics suggests a convergence between data science and business intelligence roles. Furthermore, automation and AI-powered analytics are shaping the future of these professions, emphasizing the need for adaptability and continuous learning.\n\n\nThe Essential Competencies of Data Scientists: A Framework for Hiring and Training\nThe article, The Essential Competencies of Data Scientists: A Framework for Hiring and Training by Motahareh Zarefard and Nicola Marsden (Zarefard & Marsden, 2024), investigates the skills needed for data scientists in 2024 and â€˜lookingâ€™ ahead into the future. As stated in the article, an increasing demand for data scientists and a reported difficulty in finding qualified professionals, the authors identify and categorize 130 distinct competencies across seven KSAEOs that are deemed to be essential for success within the role.\nThese include: 1) functional, 2) ethical, 3) cognitive, 4) awareness, 5) social, 6) organizational, and 7) behavioral skills.\n\nFunctional includes technical skills like machine learning comprehension and programing.\nEthical covers responsible data usage and compliance.\nCognitive includes analytical thinking, problem-solving, and creativity.\nAwareness highlights organizational knowledge, social intelligence, and self-awareness.\nSocial covers communication skills, teamwork, and leadership skills.\nOrganizational relates to managerial and strategic proficiencies.\nLastly, behavioral involves adaptableness, resilience, and even mentions the entrepreneurial spirit.\n\nThe study uses data analytics methods that combine literature review, statistical analysis, and text mining to classify and measure the defined skills. By combining information from job postings and from within industry, a model is created. The model provides a deeper insight into the competencies and can be used for optimized training and professional development (plus academic as well). Their conclusions ultimately demonstrate that those who are well-rounded [a balance of both technical and non-technical skills] are best positioned to succeed in data analytics roles.\n\n\nEvolution of Job Descriptions in 2024 with AI/ML Expertise\nAccording to the article Artificial Intelligence and Employment Transformation: A MultiSector Analysis of Workforce Disruption and Adaptation by Kanagarla Krishna Prasanth Brahmaji (2024), job descriptions have evolved significantly in 2024 to reflect the growing demand for AI/ML expertise (Kanagarla, 2024).\nThe study highlights the following key changes:\n\nIncreased Demand for AI/ML Skills: A 75% increase in demand for data analytics skills and a 41% gap in AI/ML expertise across various sectors have emerged as critical concerns for employers.\nSector-Specific Evolution: Manufacturing (43% adoption), Financial Services (39% implementation), Healthcare (41% growth) show significant AI/ML integration.\nSkill Profile Adjustments: 92% of job roles now require multi-domain digital competencies, with cross-functional expertise earning professionals a 45% salary premium.\nTraining and Development Shifts: A 163% increase in digital skills training programs underscores the need for continuous learning.\n\n\n\nIndustries Hiring the Most Data Scientists and Why\nThe demand for data scientists has surged across multiple industries as businesses increasingly rely on artificial intelligence (AI), machine learning, and big data analytics to drive decision-making. According to recent studies, the data science job market is projected to grow by 35% between 2022 and 2032.\nKey Industries Driving Data Science Hiring\n\nHealthcare and Biomedicine: AI-driven medical research and predictive diagnostics are expanding (Bzdok et al., 2024), with the healthcare analytics market expected to reach $129.7 billion by 2028.\nFinance and Banking: The financial analytics market, growing at an 11.3% CAGR, utilizes data science for fraud detection, risk assessment, and algorithmic trading.\nTechnology and AI: The technology sector drives demand for professionals in NLP, robotics, and cloud computing, with the AI market projected to hit $2 trillion by 2030.\nRetail and E-commerce: E-commerce companies use AI for supply chain optimization and customer personalization, with the market expected to reach $11.1 billion by 2028.\nGovernment and Public Policy: Data science aids urban planning, national security, and policy analysis.\n\n\n\nCareer Outlook for Business Analytics Professionals\nThe career outlook for business analytics professionals is exceptionally promising due to the growing reliance on data-driven decision-making across industries. Organizations are increasingly seeking individuals who can analyze complex datasets to optimize operations and support strategic decision-making (Noble Desktop, 2024).\nFactors Influencing Career Growth\n\nHigh Demand Across Industries: Data analytics professionals are in high demand in finance, healthcare, technology, and consulting.\nEducational Pathways and Skill Development: Universities are introducing programs to address the skill gap.\nCareer Advancement Opportunities: Roles such as senior business analyst, project manager, and CIO present potential growth paths.\n\n\n\nConclusion\nThe increasing reliance on data-driven insights is propelling the demand for professionals skilled in data science, business analytics, and machine learning. As industries continue to evolve with technological advancements, these fields promise robust career prospects and opportunities for innovation.\n\n\nReferences\n\nUmamaheswaran, S., Fernandes, S., Venkatesh, V. G., Avula, N., & Shi, Y. (2023). What Do Employers Look for in Business Analytics Roles? â€“ A Skill Mining Analysis. Information Systems Frontiers. https://doi.org/10.1007/s10796-023-10437-y\nMusazade, N. (2022). Understanding the relevant skills for data analytics-related positions: An empirical study of job advertisements [Masterâ€™s thesis]. https://www.doria.fi/bitstream/handle/10024/184705/musazade_nurlan.pdf\nZarefard, M., & Marsden, N. (2024). The essential competencies of data scientists: A framework for hiring and training. In H. Mori & Y. Asahi (Eds.), HCII 2024, LNCS 14691 (pp.Â 397â€“418). Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-60125-5_27\nNoble Desktop. (2024). Business Analyst Job Outlook. https://www.nobledesktop.com/careers/business-analyst/job-outlook\nTandfonline. (2024). Trends in Business Analytics Education. Journal of Business Analytics, 35(3), 325-376. https://doi.org/10.1080/26939169.2024.2393427\nSacred Heart University. (2024). Everything You Should Know About the Business Analytics Career Path. https://shuconnect.sacredheart.edu/blog/2024/02/09/everythingyou-should-know-about-the-business-analytics-career-path/\nKanagarla, K. P. B. (2024). Artificial intelligence and employment transformation: A multisector analysis of workforce disruption and adaptation. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.5015970\nBzdok, D., Thieme, A., Levkovskyy, O., Wren, P., Ray, T., & Reddy, S. (2024). Data science opportunities of large language models for neuroscience and biomedicine. Neuron, 112(1), 1-16. https://doi.org/10.1016/j.neuron.2024.01.016\nYosifova, A. (2024, February 29). Data scientist job market 2024: Analysis, trends, opportunities. 365 Data Science. https://365datascience.com/career-advice/data-scientistjob-market/\nU.S. Bureau of Labor Statistics (BLS). (2024). Occupational Outlook for Data Scientists. https://www.bls.gov/ooh/math/data-scientists.htm\n\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "In this project, we explore how job seekers in 2024 can position themselves effectively in the evolving job market, particularly in Data Science, Business Analytics, and Machine Learning roles. Instead of analyzing hiring trends from a recruiterâ€™s perspective, we focus on the job seekerâ€™s strategy in a changing landscape shaped by AI adoption, industry demands, and workforce shifts."
  },
  {
    "objectID": "about.html#project-overview",
    "href": "about.html#project-overview",
    "title": "About",
    "section": "",
    "text": "In this project, we explore how job seekers in 2024 can position themselves effectively in the evolving job market, particularly in Data Science, Business Analytics, and Machine Learning roles. Instead of analyzing hiring trends from a recruiterâ€™s perspective, we focus on the job seekerâ€™s strategy in a changing landscape shaped by AI adoption, industry demands, and workforce shifts."
  },
  {
    "objectID": "about.html#key-research-questions",
    "href": "about.html#key-research-questions",
    "title": "About",
    "section": "Key Research Questions",
    "text": "Key Research Questions\n\nWhat are the most in-demand skills for data science, business analytics, and ML roles in 2024?\nHow have job descriptions evolved to require AI/ML expertise?\nWhich industries are hiring the most data scientists, and why?\nWhat is the career outlook for business analytics professionals?\nHow can job seekers adapt to hiring trends, salary expectations, and the shift towards remote work?"
  },
  {
    "objectID": "about.html#skills-and-learning-outcomes",
    "href": "about.html#skills-and-learning-outcomes",
    "title": "About",
    "section": "Skills and Learning Outcomes",
    "text": "Skills and Learning Outcomes\nThis project enhances our skills in:\nData Analytics â€“ Extracting insights from real-world job market data.\nLabor Market Research â€“ Analyzing industry trends, salaries, and AIâ€™s impact.\nGitHub Workflows â€“ Collaborating through version control and project tracking.\nQuarto Documentation â€“ Structuring and publishing research for public access.\nPersonal Career Strategy â€“ Developing a data-driven roadmap for career success."
  },
  {
    "objectID": "about.html#tools-technologies",
    "href": "about.html#tools-technologies",
    "title": "About",
    "section": "Tools & Technologies",
    "text": "Tools & Technologies\n\nPython / R for data analysis\nGitHub for collaboration and version control\nQuarto for research documentation\nJob Market Data Sources for insights"
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction: Business Analytics, Data Science, and Machine Learning Trends",
    "section": "",
    "text": "Below is the rationale statement for our research."
  },
  {
    "objectID": "research_introduction.html#rationale-statement",
    "href": "research_introduction.html#rationale-statement",
    "title": "Research Introduction: Business Analytics, Data Science, and Machine Learning Trends",
    "section": "ğŸ“„ Rationale Statement",
    "text": "ğŸ“„ Rationale Statement\nFirstly, on behalf of all of us in Group 1 - welcome.\nAfter careful consideration, we have collectively chosen to focus our research efforts on Business Analytics, Data Science, and Machine Learning Trends. The primary motivation for selecting this topic is that, in the long run, a deeper understanding of these areas will significantly strengthen our professional expertise and career prospects. Among the various research options available, we believe this theme holds the greatest potential for long-term impact as we pursue careers in the business analytics and data science disciplines.\nOur goal is to conduct thorough and insightful research that provides a reliable understanding of the industryâ€™s landscape at large. As is outlined in the assignment description, we aim to explore the most in-demand skills, examine how job descriptions have evolved in recent years, identify the leading employers of both business analysts and data scientists, and to assess the career outlook of these roles.\nIf approached strategically, the exploration will serve as a valuable resource, providing knowledge we can revisit and build upon throughout our careers - even as the industry continues to evolve.\nSincerely,\nTeam 1\n\nMoiz Deshmukh\nPrabu Jayabalan\nAndrey Pafnutyev\nJason Stopas\n\n\nDownload the PDF"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "ğŸ“Œ Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Top 15 Job Posting Industries\n\ntop_industries = df[\"NAICS_2022_6_NAME\"].value_counts().nlargest(15)\nfig = px.pie(\n    names=top_industries.index, \n    values=top_industries.values, \n    title=\"Top 15 Job Posting Industries\"\n)\nfig\n\n        \n        \n        \n\n\n                            \n                                            \n\n\n\n\n\nTop 15 Job Posting Industries\n\n\nIn our analysis, we looked at the top industries with the most job postings to get a sense of where the demand is highest. The pie chart shows that 22.6% of the postings fall under the Unclassified Industry category, suggesting that many roles either span multiple sectors or lack clear classification. This made us consider the potential limitations in how industries are labeled in the data.\nWe also noticed a strong demand for skills in technology and consulting. For example, Custom Computer Programming Services made up 12.1% of the postings, while Management Consulting Services accounted for 11.3%. This highlights a significant need for both tech and management skills in todayâ€™s job market.\nInterestingly, several tech-focused industries, such as Software Publishers and Computer Systems Design Services, showed up prominently in the chart. This aligns with the growing demand for IT and consulting professionals, which didnâ€™t surprise us given the ongoing digital transformation across industries.\nWe also found that finance and healthcare sectors have a notable share of job postings, indicating steady demand in these fields. On the flip side, areas like Accounting and Temporary Help Services had fewer listings, suggesting these might be more niche markets.\n\n\n\nMonthly Trend of Data-Related Job Postings by Role\n\n# 1. Filter the main df into df_roles\ndf_roles = df[df[\"TITLE_NAME\"].str.contains(\" Data Analysts|Business Intelligence Analysts|Data Analytics Engineers|Data and Reporting Analysts|\"\n    \"Data Governance Analysts|Data Quality Analysts|Data Analytics Analysts|Data Management Analysts|\"\n    \"Data Modelers|Lead Data Analysts|Research Data Analysts|IT Data Analysts|Data Analytics Manager|\"\n    \"Lead Business Intelligence Analysts|Data Science Analysts|Data Analytics Leads|\"\n    \"Business Intelligence Data Analysts|Data Operations Analysts|Health Data Analysts|\"\n    \"Data analytics consultants|Enterprise Data Analysts\", case=False, na=False)]\n\n# 1. Make a copy to avoid SettingWithCopyWarning\ndf_roles = df_roles.copy()\n\n# 2. Convert POSTED to datetime (if not already)\ndf_roles[\"POSTED\"] = pd.to_datetime(df_roles[\"POSTED\"])\n\n# 3. Create a monthly column as a Timestamp\ndf_roles[\"month\"] = df_roles[\"POSTED\"].dt.to_period(\"M\").dt.to_timestamp()\n\n# 4. Group by month and role\nmonthly_counts = df_roles.groupby([\"month\", \"TITLE_NAME\"]).size().reset_index(name=\"count\")\n\nfig = px.area(\n    monthly_counts,\n    x=\"month\",\n    y=\"count\",\n    color=\"TITLE_NAME\",\n    title=\"Monthly Trend of Data-Related Job Postings by Role (Stacked Area)\"\n)\nfig.show()\n\n                            \n                                            \n\n\n\n\n\nMonthly Trend of Data-Related Job Postings by Role\n\n\nIn the above Stacked Area Chart, we focused on understanding the monthly trends for various data-related job roles. To do this, we filtered the dataset to include only job titles containing keywords like â€œData Analysts,â€ â€œBusiness Intelligence Analysts,â€ and â€œData Engineers,â€ among others. After filtering, we converted the posting dates into a proper datetime format and created a new column to track monthly trends. We then grouped the data by month and job title to visualize how the demand for these roles evolved over time.\nThe stacked area chart we generated illustrates that the demand for data-related roles has shown a consistent upward trend, especially after mid-June 2024. One of the most noticeable patterns is the significant share held by roles such as Big Data Analysts and Business Intelligence Analysts, which suggests that organizations are increasingly seeking professionals who can handle large-scale data analysis and provide actionable insights.\nInterestingly, we observed that the demand for Data Analysts and Data Analytics Engineers also increased steadily, indicating a growing need for professionals who can not only interpret data but also manage the infrastructure required for analysis. This aligns with the broader industry trend of integrating advanced analytics into decision-making processes.\nWe also found that more specialized roles like Clinical Data Analysts and Customer Data Analysts are gaining traction, although they represent a smaller share of the total postings. This could imply that industries such as healthcare and customer analytics are gradually expanding their analytics teams.\n\n\n\nRemote vs.Â On-Site Jobs (Data Roles)\n\nfig = px.pie(df_roles, names=\"REMOTE_TYPE_NAME\", title=\"Remote vs. On-Site Jobs\")\nfig.show()\n\n                            \n                                            \n\n\n\n\n\nRemote vs.Â On-Site Jobs\n\n\nWe created a Pie Chart to explor the distribution of remote, on-site, and hybrid roles for data-related jobs. The chart shows that 73.8% of postings do not specify a preference, suggesting either data gaps or employer flexibility. Among specified roles, 20.4% are remote, indicating a strong demand for remote work. Hybrid roles account for 4%, while fully on-site roles are only 1.79%.\nThese findings suggest a clear shift towards remote and flexible work arrangements in the data field. Highlighting remote work skills could be advantageous for job seekers in this area.\n\n\n\nData-Related Job Postings Across the USA\n\n# ğŸ”¹ Step 2: Aggregate Job Counts by State\njob_counts = df_roles[\"STATE_NAME\"].value_counts().reset_index()\njob_counts.columns = [\"state\", \"job_postings\"]\n\n# ğŸ”¹ Step 3: Convert Full State Names to Abbreviations\njob_counts[\"state\"] = job_counts[\"state\"].apply(lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else x)\n\n# ğŸ”¹ Step 4: Create Choropleth Map\nfig = px.choropleth(\n    job_counts,\n    locations=\"state\",\n    locationmode=\"USA-states\",  # Correct location mode for US states\n    color=\"job_postings\",  # Color by job count\n    hover_name=\"state\",\n    color_continuous_scale=\"Viridis\",  # High-contrast color scheme\n    title=\"Data-Related Job Postings Across the USA\",\n    scope=\"usa\"  # Focus on the USA\n)\n\nfig.show()\n\n                            \n                                            \n\n\n\n\n\nData-Related Job Postings Across the USA\n\n\nWe created a Choropleth Map to understand the geographical distribution of data-related job postings across the United States. To do this, we aggregated the job counts by state and converted full state names to abbreviations to ensure consistency in the map. We then used a choropleth map to visualize how job postings are spread across different states.\nFrom the map, we can see that states like California, Texas, and Florida have the highest concentrations of data-related job postings, indicated by the brighter yellow shades. This pattern suggests that these states are major hubs for data-related roles, likely due to their large tech industries and the presence of major corporations.\nIn contrast, several states in the Midwest and some in the Mountain region show darker shades, indicating fewer job opportunities in data-related fields. This could imply either a lower demand for such roles or a smaller tech industry presence in those areas.\n\n\n\nIndustries Having Data-Related Roles\n\n# Get industries associated with these roles\nindustry_text = \" \".join(df_roles[\"NAICS_2022_6_NAME\"].dropna())\n\n# Generate word cloud\nwordcloud = WordCloud(\n    width=800, height=400, background_color=\"white\", \n    colormap=\"viridis\", max_words=100\n).generate(industry_text)\n\n# Display the word cloud\nplt.figure(figsize=(12, 6))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title(\"Industries Having Data-Related Roles\", fontsize=14)\nplt.show()\n\n\n\n\n\n\n\n\nWith this WordCloud, we aimed to identify the industries that most frequently offer data-related roles. We extracted industry names from the dataset, combined them into a single text string, and then generated a word cloud to visualize which industries appeared most often.\nFrom the word cloud, we can see that â€œUnclassified Industry,â€ â€œProgramming Services,â€ â€œConsulting Services,â€ and â€œInsurance Carriersâ€ are some of the most prominent terms. The large size of these words suggests that these industries have a significant number of data-related job postings. This pattern highlights the growing importance of data roles in both tech-heavy sectors like programming and consulting as well as in more traditional fields such as insurance.\nOther notable industries in the word cloud include â€œComputer Systems Design,â€ â€œEmployment Placement Agencies,â€ and â€œDirect Health Services.â€ Their visibility suggests a broad demand for data professionals across diverse sectors, emphasizing that data analytics skills are valuable beyond just the tech industry.\nThis indicate that the demand for data roles is not limited to a few industries but is spread across both tech-focused and traditional sectors. This reinforces the idea that data skills are becoming essential across the board.\n\n\n\nğŸ“Œ Key Findings\n\nIndustry Demand:\n\n\nProgramming Services, Consulting Services, and Insurance emerged as leading industries for data-related roles, indicating a widespread need for data skills beyond traditional tech sectors.\nThe prominence of Unclassified Industry suggests potential gaps in data classification or a diverse range of roles that do not fit into conventional categories.\n\n\nGeographical Distribution:\n\n\nCalifornia, Texas, and Florida were identified as major hubs for data-related jobs, while several Midwestern and Mountain states showed fewer opportunities.\nThis pattern suggests that professionals may find more job prospects by focusing on these high-demand states.\n\n\nWork Arrangement Preferences:\n\n\nA significant share of job postings preferred remote and hybrid roles, with over 20% specifically offering remote options.\nThe limited proportion of fully on-site roles reflects a broader shift towards flexible work models in the data industry.\n\n\nRole-Specific Trends:\n\n\nThere is a clear upward trend in demand for roles such as Big Data Analysts and Business Intelligence Analysts, highlighting the growing importance of both technical and analytical skills.\nSpecialized roles like Clinical Data Analysts and Customer Data Analysts are also gaining traction, indicating expanding opportunities in niche areas.\n\n\n\n\nğŸ“Œ Conclusion\nOur analysis revealed that the demand for data-related skills is both substantial and diverse, spanning multiple industries and regions across the United States. Key sectors such as tech, consulting, and insurance show the most significant opportunities, while states like California, Texas, and Florida lead in job postings.\nThe strong preference for remote and hybrid roles highlights the importance of flexibility in the current job market. Meanwhile, the consistent rise in demand for specialized data roles suggests a promising outlook for professionals equipped with both analytical and domain-specific skills.\nOverall, these findings suggest that focusing on high-demand industries, enhancing remote work capabilities, and acquiring specialized skills can significantly boost job prospects in the data field."
  },
  {
    "objectID": "working_files/analysis_files/data_analysis_2.html",
    "href": "working_files/analysis_files/data_analysis_2.html",
    "title": "Business Running Case: Evaluating Personal Job Market Prospects in 2024",
    "section": "",
    "text": "import polars as pl\nimport pandas as pd\nimport sqlite3\nimport plotly.express as px\nimport missingno as msno\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image\n\n\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\n\n\ndf.head()\n\n\n\n\n\n\n\n\nID\nLAST_UPDATED_DATE\nLAST_UPDATED_TIMESTAMP\nDUPLICATES\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nURL\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n1f57d95acf4dc67ed2819eb12f049f6a5c11782c\n2024-09-06\n2024-09-06 20:32:57.352 Z\n0\n2024-06-02\n2024-06-08\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\n[\\n \"https://sjobs.brassring.com/TGnewUI/Sear...\n...\n44\nRetail Trade\n441\nMotor Vehicle and Parts Dealers\n4413\nAutomotive Parts, Accessories, and Tire Retailers\n44133\nAutomotive Parts and Accessories Retailers\n441330\nAutomotive Parts and Accessories Retailers\n\n\n1\n0cb072af26757b6c4ea9464472a50a443af681ac\n2024-08-02\n2024-08-02 17:08:58.838 Z\n0\n2024-06-02\n2024-08-01\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\n[\\n \"https://joblink.maine.gov/jobs/1085740\"\\n]\n...\n56\nAdministrative and Support and Waste Managemen...\n561\nAdministrative and Support Services\n5613\nEmployment Services\n56132\nTemporary Help Services\n561320\nTemporary Help Services\n\n\n2\n85318b12b3331fa490d32ad014379df01855c557\n2024-09-06\n2024-09-06 20:32:57.352 Z\n1\n2024-06-02\n2024-07-07\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\n[\\n \"https://dejobs.org/dallas-tx/data-analys...\n...\n52\nFinance and Insurance\n524\nInsurance Carriers and Related Activities\n5242\nAgencies, Brokerages, and Other Insurance Rela...\n52429\nOther Insurance Related Activities\n524291\nClaims Adjusting\n\n\n3\n1b5c3941e54a1889ef4f8ae55b401a550708a310\n2024-09-06\n2024-09-06 20:32:57.352 Z\n1\n2024-06-02\n2024-07-20\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\n[\\n \"https://www.disabledperson.com/jobs/5948...\n...\n52\nFinance and Insurance\n522\nCredit Intermediation and Related Activities\n5221\nDepository Credit Intermediation\n52211\nCommercial Banking\n522110\nCommercial Banking\n\n\n4\ncb5ca25f02bdf25c13edfede7931508bfd9e858f\n2024-06-19\n2024-06-19 07:00:00.000 Z\n0\n2024-06-02\n2024-06-17\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\n[\\n \"https://modesto.craigslist.org/sls/77475...\n...\n99\nUnclassified Industry\n999\nUnclassified Industry\n9999\nUnclassified Industry\n99999\nUnclassified Industry\n999999\nUnclassified Industry\n\n\n\n\n5 rows Ã— 131 columns\n\n\n\n\nprint(df.shape)\n\n(72476, 131)\n\n\n\nğŸ“Œ Data Cleaning & Preprocessing\nDrop Unnecessary Columns\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True)\n\nWe are removing multiple versions of NAICS/SOC codes because we are going to use the most granular version of those codes available.\nIn this case it is NAICS and SOC codes. Keeping multiple versions would introduce redundancy and potential inconsistencies in our analysis.\nThe following columns are irrelevant or redundant for our analysis and can be dropped to improve efficiency and clarity.\nID - unique identifier which is not relevant for analysis\nURL - job posting urls which is not relevant for analysis\nACTIVE_URLS - active urls for job posting which is not relevant for analysis\nDUPLICATES - whether the job post is duplicate or not\nLAST_UPDATED_TIMESTAMP - timestamp when the job post was updated\nNAICS2CS3, NAICS4, NAICS5, NAICS6, NAI- less granular versions of NAICS code (we only need NAICS)\nSOC_2, SOC_3, SOC_5 - less granular versions of SOC codes (we only need SOC)\nDropping these columns will improve our analysis by:\n- Reducing the size of the dataset - Removing irrelevant information - Improving the clarity and focus of our analysis by removing unnecessary details.\nHandling Missing Values\n\nmsno.heatmap(df)\nplt.title(\"Missing Data Heatmap\")\nplt.show()  \n\n\n\n\n\n\n\n\n\n# Drop columns with &gt;50% missing values\ndf.dropna(thresh=len(df) * 0.5, axis=1, inplace=True)\n\n# Fill missing values safely\ndf[\"NAICS_2022_6\"] = df[\"NAICS_2022_6\"].fillna(df[\"NAICS_2022_6\"].median())\ndf[\"NAICS_2022_6_NAME\"] = df[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\")\n\nRemove Duplicates\nTo ensure each job is counted only once, we remove duplicates based on job title, company, location, and posting date.\n\ndf = df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\n\nğŸ“Œ Exploratory Data Analysis (EDA)\nJob Postings by Industry\n\ntop_industries = df[\"NAICS_2022_6_NAME\"].value_counts().nlargest(15)\nfig = px.pie(\n    names=top_industries.index, \n    values=top_industries.values, \n    title=\"Top 15 Job Posting Industries\"\n)\nfig\n\n                                                \n\n\nTop 20 Industries by Median Salary\nRemote vs.Â On-Site Jobs\n\nfig = px.pie(df, names=\"REMOTE_TYPE_NAME\", title=\"Remote vs. On-Site Jobs\")\nfig.show()\n\n                                                \n\n\nData-Related Job Postings Across the USA\n\nimport plotly.express as px\nimport pandas as pd\nimport us  # To convert full state names to abbreviations\n\n# ğŸ”¹ Step 1: Filter for Data-Related Roles\ndata_roles = df[df[\"NAICS_2022_6_NAME\"].str.contains(\n    \"Data|Analytics|Machine Learning|Data Scientist|ML|Business Analyst|Data Analyst | \", \n    case=False, na=False\n)]\n\n# ğŸ”¹ Step 2: Aggregate Job Counts by State\njob_counts = data_roles[\"STATE_NAME\"].value_counts().reset_index()\njob_counts.columns = [\"state\", \"job_postings\"]\n\n# ğŸ”¹ Step 3: Convert Full State Names to Abbreviations\njob_counts[\"state\"] = job_counts[\"state\"].apply(lambda x: us.states.lookup(x).abbr if us.states.lookup(x) else x)\n\n# ğŸ”¹ Step 4: Create Choropleth Map\nfig = px.choropleth(\n    job_counts,\n    locations=\"state\",\n    locationmode=\"USA-states\",  # Correct location mode for US states\n    color=\"job_postings\",  # Color by job count\n    hover_name=\"state\",\n    color_continuous_scale=\"Viridis\",  # High-contrast color scheme\n    title=\"Data-Related Job Postings Across the USA\",\n    scope=\"usa\"  # Focus on the USA\n)\n\nfig.show()\n\n                                                \n\n\nIndustries related to data roles\n\ndata_roles = df[df[\"NAICS_2022_6_NAME\"].str.contains(\n    \"Data|Analytics|Machine Learning|Data Scientist|ML|Business Analyst| Data Analyst|\", \n    case=False, na=False\n)]\n\nindustry_text = \" \".join(data_roles[\"NAICS_2022_6_NAME\"].dropna())\n\nwordcloud = WordCloud(\n    width=800, height=400, background_color=\"white\", \n    colormap=\"viridis\", max_words=100\n).generate(industry_text)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title(\"Industries with Data-Related Roles\")\nplt.show()"
  }
]